{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMmwZf4jDI7JfbPfMYixgcs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alexandra-SR/PI_2/blob/master/p3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbS-4_hrz0c3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "65a44097-8ebd-455a-f900-5b6edc72cb2e"
      },
      "source": [
        "!pip install face_recognition"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from face_recognition) (1.18.5)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |████████████████████████████████| 100.2MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (19.18.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from face_recognition) (7.0.0)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566173 sha256=bbbc14cfc84eee964ca7b1138b43e62f3a0e24e9858fee94fd32550461e74705\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSrF1OPG2xlM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "4561688d-de2f-478f-a81f-730d9ffc9c08"
      },
      "source": [
        "!mkdir known\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Bill_Gates_2014.jpg/454px-Bill_Gates_2014.jpg -O known/bill.jpg\n",
        "!wget https://i.pinimg.com/736x/39/ab/f5/39abf539e80f88a1bc53781946743e36.jpg -O known/sara.jpg\n",
        "!wget https://tentulogo.com/wp-content/uploads/Mark-Zuckerberg.jpg -O known/mark.jpg"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-24 20:48:37--  https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Bill_Gates_2014.jpg/454px-Bill_Gates_2014.jpg\n",
            "Resolving upload.wikimedia.org (upload.wikimedia.org)... 103.102.166.240, 2001:df2:e500:ed1a::2:b\n",
            "Connecting to upload.wikimedia.org (upload.wikimedia.org)|103.102.166.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 56604 (55K) [image/jpeg]\n",
            "Saving to: ‘known/bill.jpg’\n",
            "\n",
            "known/bill.jpg      100%[===================>]  55.28K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2020-09-24 20:48:38 (664 KB/s) - ‘known/bill.jpg’ saved [56604/56604]\n",
            "\n",
            "--2020-09-24 20:48:38--  https://i.pinimg.com/736x/39/ab/f5/39abf539e80f88a1bc53781946743e36.jpg\n",
            "Resolving i.pinimg.com (i.pinimg.com)... 23.193.24.222, 2600:1417:76:4a2::1931, 2600:1417:76:49f::1931, ...\n",
            "Connecting to i.pinimg.com (i.pinimg.com)|23.193.24.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 96521 (94K) [image/jpeg]\n",
            "Saving to: ‘known/sara.jpg’\n",
            "\n",
            "known/sara.jpg      100%[===================>]  94.26K   300KB/s    in 0.3s    \n",
            "\n",
            "2020-09-24 20:48:38 (300 KB/s) - ‘known/sara.jpg’ saved [96521/96521]\n",
            "\n",
            "--2020-09-24 20:48:39--  https://tentulogo.com/wp-content/uploads/Mark-Zuckerberg.jpg\n",
            "Resolving tentulogo.com (tentulogo.com)... 77.246.188.204\n",
            "Connecting to tentulogo.com (tentulogo.com)|77.246.188.204|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 135712 (133K) [image/jpeg]\n",
            "Saving to: ‘known/mark.jpg’\n",
            "\n",
            "known/mark.jpg      100%[===================>] 132.53K   158KB/s    in 0.8s    \n",
            "\n",
            "2020-09-24 20:48:41 (158 KB/s) - ‘known/mark.jpg’ saved [135712/135712]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI4wpnwl0QUa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "8c047eeb-c50c-475e-fec7-2bcb0cfb9bce"
      },
      "source": [
        "import numpy as np\n",
        "import face_recognition as fr\n",
        "import cv2\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#video_capture = cv2.VideoCapture(0)\n",
        "\n",
        "def read_img(path):\n",
        "  img = cv2.imread(path)\n",
        "  (h, w) = img.shape[:2]\n",
        "  width = 500\n",
        "  ratio = width/float(w)\n",
        "  height = int(h*ratio)\n",
        "  return cv2.resize(img,(width, height))\n",
        "\n",
        "known_encodings = []\n",
        "known_names = []\n",
        "known_dir = 'known'\n",
        "\n",
        "for file in os.listdir(known_dir):\n",
        "  img = read_img(known_dir + '/' + file)\n",
        "  img_enc = fr.face_encodings(img)[0]\n",
        "  known_encodings.append(img_enc)\n",
        "  known_names.append(file.split('.')[0])\n",
        "\n",
        "video_capture = cv2.VideoCapture(0 + cv2.CAP_DSHOW)\n",
        "\n",
        "while True:\n",
        "  ret, frame = video_capture.read()\n",
        "\n",
        "  #small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
        "  #rgb_small_frame = small_frame[:, :, ::-1]\n",
        "\n",
        "  rgb_frame = frame[:, :, ::-1]\n",
        "  #rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  face_locations = fr.face_locations(rgb_frame) #rgb_frame\n",
        "  face_encodings = fr.face_encodings(rgb_frame, face_locations)  #rgb_frame\n",
        "\n",
        "  for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
        "    matches = fr.compare_faces(known_encodings, face_encodings)\n",
        "    name = \"Unknown\"\n",
        "    face_distances = fr.face_distance(known_encodings, face_encodings)\n",
        "    best_match_index = np.argmin(face_distances)\n",
        "    if matches[best_match_index]:\n",
        "      name = known_names[best_match_index]\n",
        "\n",
        "    cv2.rectangle(frame, (left, top), (right, bottom), (0,0,255), 2)\n",
        "\n",
        "    cv2.rectangle(frame, (left, bottom -35), (right, bottom), (0,0,255), cv2.FILLED)\n",
        "\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    cv2.putText(frame, name, (left +6, bottom -6), font, 1.0, (255,255,255), 1)\n",
        "\n",
        "  cv2_imshow(frame)\n",
        "  # cv2_imshow('Webcam_facerecognition', frame)\n",
        "\n",
        "  if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "    break\n",
        "\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e302b5e52975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;31m#rgb_small_frame = small_frame[:, :, ::-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m   \u001b[0mrgb_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m   \u001b[0;31m#rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT46Qbl0GkIw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea759d6c-d5ec-474d-8af5-8b98ed1dc930"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKPjuDPDOPBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "...\n",
        "VIDEO_STREAM = \"/content/drive/My Drive/Colab Notebooks/Millery.avi\"\n",
        "VIDEO_STREAM_OUT = \"/content/drive/My Drive/Colab Notebooks/Result.avi\"\n",
        "...\n",
        "# initialize the video stream and pointer to output video file\n",
        "vs = cv2.VideoCapture(VIDEO_STREAM)\n",
        "writer = None\n",
        "vs.set(cv2.CAP_PROP_POS_FRAMES, 1000);\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}